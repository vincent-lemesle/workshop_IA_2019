{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de données non linéaires avec une couche cachée\n",
    "\n",
    "Bonjour et bienvenue à ce workshop dans lequel nous allons construire notre premier réseau de neurones profond (deep learning), contenant une couche cachée. Vous remarquerez une grosse différence entre ce modèle et celui que vous avez implémenté avec la régression logistique.\n",
    "\n",
    "\n",
    "**Ce que vous allez apprendre:**\n",
    "- Implémenter un réseau de neurones avec une couche cachée pour une classification à 2 classes\n",
    "- Utiliser les neurones avec une fonction d'activation non linéaire, comme la tanh\n",
    "- Calculer la loss cross-entropy\n",
    "- Implémenter les forward et backward propagations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages ##\n",
    "\n",
    "Commençons par importer les packages dont nous aurons besoin:\n",
    "- [numpy](www.numpy.org) est le package fondamental pour le calcul scientifique en Python.\n",
    "- [sklearn](http://scikit-learn.org/stable/) dispose de nombreuses fonctions pour la construction et l'analyse des données. \n",
    "- [matplotlib](http://matplotlib.org) est une librairie pour afficher des graphes, tableaux, etc. en Python.\n",
    "- tests fournit quelques exemples tests pour vérifier vos fonctions\n",
    "- utils fournit de nombreuses fonctions utiles dont nous avons besoin pour ce notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tests import *\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from utils import plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1) # seed pour comparer avec les valeurs attendues, ne pas modifier !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Dataset ##\n",
    "\n",
    "Tout d'abord, récupérons le jeu de données. Le code suivant va initialiser un jeu de données \"fleur\" à 2 classes dans les  variables `X` et `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, Y = load_planar_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisez le jeu de données avec matplotlib. Les données ressemblent à une \"fleur\" avec des points rouges (label y = 0) et bleus (y = 1). Votre but est de construire un modèle qui classeront correctement ces données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = []\n",
    "for i in range(Y.shape[1]):\n",
    "    if i < Y.shape[1] / 2: c.append('red')\n",
    "    else: c.append('blue')\n",
    "plt.scatter(X[0, :], X[1, :], c=c, s=40, cmap=plt.cm.Spectral);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez:\n",
    "    - un numpy-array (matrix) X qui contient vos features (x1, x2)\n",
    "    - un numpy-array (vecteur) Y qui contient vos labels (rouge:0, bleu:1).\n",
    "\n",
    "Analysons davantage nos données.\n",
    "\n",
    "**Exercice**: Combien d'exemples de train avez vous ? De plus, quels sont les shapes des variables `X` et `Y`? \n",
    "\n",
    "**Indice**: Comment récupérez vous le shape d'un numpy array ? [(help)](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Début du code ### (≈ 3 lignes de code)\n",
    "shape_X = None\n",
    "shape_Y = None\n",
    "### Fin du code ###\n",
    "\n",
    "print ('Le shape de X est: ' + str(shape_X))\n",
    "print ('Le shape de Y est: ' + str(shape_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultat attendu**:\n",
    "       \n",
    "<table style=\"width:20%\">\n",
    "  \n",
    "  <tr>\n",
    "    <td>shape de X</td>\n",
    "    <td> (2, 400) </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>shape de Y</td>\n",
    "    <td>(1, 400) </td> \n",
    "  </tr>\n",
    "\n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Simple régression logistiaue\n",
    "\n",
    "Avant de construire un réseau de neurones complet, visualisons les performances de la régression logistique à ce problème. Vous pouvez utilisez les fonctions de sklearn pour le faire. Exécutez la cellule suivant pour entraîner une régression logistique sur notre jeu de données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Entrainement du classifier régression logistique\n",
    "clf = sklearn.linear_model.LogisticRegressionCV(cv=5);\n",
    "clf.fit(X.T, Y.T.ravel());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant plotter le decision boundary (limite de décision) de ce modèle. Exécutez le code suivant. \n",
    "\n",
    "**Attention:** Suite à des problèmes de versions matplotlib, il se peut que vous ne voyez pas les points initiaux. L'important est de voir comment la régression logistique a apporté sa solution au problème. Appelez un assistant si vous ne comprenez pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot de la decision boundary pour la régression logistique\n",
    "try:\n",
    "    plot_decision_boundary(lambda x: clf.predict(x), X, Y)\n",
    "except:\n",
    "    print(\"Suite à un problème de version matplotlib, vous ne voyez pas les points initiaux. Reprenez le graphique précédent et imaginez les points comme étant plot.\")\n",
    "    pass\n",
    "plt.title(\"Régression logistique\")\n",
    "\n",
    "# Print l'accuracy\n",
    "LR_predictions = clf.predict(X.T)\n",
    "print ('Accuracy de la régression logistique: %d ' % float((np.dot(Y,LR_predictions) + np.dot(1-Y,1-LR_predictions))/float(Y.size)*100) +\n",
    "       '% ' + \"de points labellisés corrects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultat attendu**:\n",
    "\n",
    "<table style=\"width:20%\">\n",
    "  <tr>\n",
    "    <td>Accuracy</td>\n",
    "    <td> 47% </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: Ce jeu de données n'est pas linéairement séparable, donc la logistique régression ne fonctionne pas ici. Heureusement, un réseau de neurones profond pourra résoudre notre problème. C'est parti ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Réseau de neurones profond\n",
    "\n",
    "La régression logistique ne fonctionne pas sur notre jeu de données. Vous allez maintenant entraîner un réseau de neurones profond avec une couche cachée.\n",
    "\n",
    "**Voici notre modèle**:\n",
    "<img src=\"images/classification_kiank.png\" style=\"width:600px;height:300px;\">\n",
    "\n",
    "**Mathématiquement**:\n",
    "\n",
    "Pour un exemple $x^{(i)}$:\n",
    "$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1]}\\tag{1}$$ \n",
    "$$a^{[1] (i)} = \\tanh(z^{[1] (i)})\\tag{2}$$\n",
    "$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2]}\\tag{3}$$\n",
    "$$\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})\\tag{4}$$\n",
    "$$y^{(i)}_{prediction} = \\begin{cases} 1 & \\mbox{si } a^{[2](i)} > 0.5 \\\\ 0 & \\mbox{sinon } \\end{cases}\\tag{5}$$\n",
    "\n",
    "A partir des prédictions calculées, vous pourrez calculer le coût grâce à la formule suivante:\n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right) \\small \\tag{6}$$\n",
    "\n",
    "**Rappel**: La méthodologie générale pour construire un réseau de neurones est la suivante:\n",
    "    1. Définir la structure du réseau de neurones ( nombre de features en entrée,  nombre de couches cachées, etc). \n",
    "    2. Initialiser les paramètres du modèle\n",
    "    3. Boucle:\n",
    "        - Implémenter la forward propagation\n",
    "        - Calcul du coût\n",
    "        - Implémenter la backward propagation pour avoir les gradients\n",
    "        - Update des paramètres \n",
    "\n",
    "Après avoir créé vos fonctions, vous allez les merger en une unique fonction qu'on nommera `nn_model()`. \n",
    "Quand ce modèle sera entraîné, vous pourrez réaliser des prédictions sur des nouvelles données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Définir la structure du réseau de neurones ####\n",
    "\n",
    "**Exercice**: Définissez 3 variables:\n",
    "    - n_x: size de la couche d'entrée\n",
    "    - n_h: size de la couche cachée (définissez la à 4) \n",
    "    - n_y: size de la couche de sortie\n",
    "\n",
    "**Indice**: Utilisez les shapes de X et Y pour trouver n_x et n_y. Hardcodez directement la couche cachée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def layer_sizes(X, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- jeu de données en entrée de shape (size en entrée, nombre d'exemples)\n",
    "    Y -- labels de shape (size en sortie, nombre d'exemples)\n",
    "    \"\"\"\n",
    "    ### Début du code ### (≈ 3 lignes de code)\n",
    "    n_x = None # size de la couche d'entrée\n",
    "    n_h = None\n",
    "    n_y = None # size de la couche de sortie\n",
    "    ### Fin du code ###\n",
    "    return (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_assess, Y_assess = layer_sizes_test_case()\n",
    "(n_x, n_h, n_y) = layer_sizes(X_assess, Y_assess)\n",
    "print(\"Size de la couche d'entrée: n_x = \" + str(n_x))\n",
    "print(\"Size de la couche cachée: n_h = \" + str(n_h))\n",
    "print(\"Size de la couche de sortie: n_y = \" + str(n_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultat attentu** (il ne s'agit pas du nombres de neurones que nous utiliserons pour notre modèle, juste un test pour vérifier votre fonction).\n",
    "\n",
    "<table style=\"width:20%\">\n",
    "  <tr>\n",
    "    <td>n_x</td>\n",
    "    <td> 5 </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td>n_h</td>\n",
    "    <td> 4 </td> \n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>n_y</td>\n",
    "    <td> 2 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 -Initialiser les paramètres du modèle ####\n",
    "\n",
    "**Exercice**: Implementez la function `initialize_parameters()`.\n",
    "\n",
    "**Instructions**:\n",
    "- Soyez sûrs que les sizes de vos paramètres sont correctes. Regardez le schéma au-dessus si nécessaire.\n",
    "- Vous initialiserez les matrices des poids avec des valeurs aléatoires\n",
    "    - Utilisez: `np.random.randn(a,b) * 0.01` pour initialiser aléatoirement une matrice de shape (a,b).\n",
    "- Vous initialisez les vectors des biais à 0.\n",
    "    - Utilisez: `np.zeros((a,b))` pour initialiser une matrice de shape (a,b) avec des zéros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size de la couche d'entrée\n",
    "    n_h -- size de la couche cachée (définissez la à 4) \n",
    "    n_y -- size de la couche de sortie\n",
    "    \n",
    "    Return:\n",
    "    params -- dictionnaire python contenant les paramètres:\n",
    "                    W1 -- matrice poids de shape (n_h, n_x)\n",
    "                    b1 -- vecteur biais shape (n_h, 1)\n",
    "                    W2 -- matrice poids shape (n_y, n_h)\n",
    "                    b2 -- vecteur biais shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(42) # ne pas modifier le seed, il nous servira à comparer nos résultats\n",
    "    \n",
    "    ### Début du code ### (≈ 4 lignes de code)\n",
    "    W1 = None\n",
    "    b1 = None\n",
    "    W2 = None\n",
    "    b2 = None\n",
    "    ### Fin du code ###\n",
    "    \n",
    "    assert (W1.shape == (n_h, n_x))\n",
    "    assert (b1.shape == (n_h, 1))\n",
    "    assert (W2.shape == (n_y, n_h))\n",
    "    assert (b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_x, n_h, n_y = initialize_parameters_test_case()\n",
    "\n",
    "parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultat attendu**:\n",
    "\n",
    "<table style=\"width:90%\">\n",
    "  <tr>\n",
    "    <td>W1</td>\n",
    "    <td> [[ 0.00496714 -0.00138264]\n",
    " [ 0.00647689  0.0152303 ]\n",
    " [-0.00234153 -0.00234137]\n",
    " [ 0.01579213  0.00767435]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>b1</td>\n",
    "    <td> [[ 0.]\n",
    " [ 0.]\n",
    " [ 0.]\n",
    " [ 0.]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>W2</td>\n",
    "    <td> [[-0.00469474  0.0054256  -0.00463418 -0.0046573 ]]</td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "  <tr>\n",
    "    <td>b2</td>\n",
    "    <td> [[ 0.]] </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 -La boucle ####\n",
    "\n",
    "**Exercice**: Implementez `forward_propagation()`.\n",
    "\n",
    "**Instructions**:\n",
    "- Regardez au-dessus les formules mathématiques de votre modèle.\n",
    "- Vous pouvez utiliser la fonction `sigmoid()`. Nous l'avons défini et importé au début depuis utils.\n",
    "- Vous pouvez utiliser la fonction `np.tanh()`. C'est une fonction de la lib numpy.\n",
    "- Les étapes que vous devez implémenter sont les suivantes:\n",
    "    1. Récuperez chaque paramètre à partir du dictionnaire python \"parameters\" (qui correspond à l'output de `initialize_parameters()`). \n",
    "    2. Implémentez la forward propagation. Calculez $Z^{[1]}, A^{[1]}, Z^{[2]}$ et $A^{[2]}$. Rappel: Z correspond à la pré-activation et A à l'activation.\n",
    "- Les valeurs dont vous aurez besoin pour la backpropagation sont stockées dans \"`cache`\". Le dictionnaire `cache` sera un argument de la fonction backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- données en entrée de size (n_x, m)\n",
    "    parameters -- dictionnaire python contenant vos paramètres (poids et biais)\n",
    "    \n",
    "    Return:\n",
    "    A2 -- L'output de la sigmoïde de la deuxième activation\n",
    "    cache -- dictionnaire contenant \"Z1\", \"A1\", \"Z2\" et \"A2\"\n",
    "    \"\"\"\n",
    "    # Récupérez chaque paramètre du dictionnaire \"parameters\"\n",
    "    ### Début du code ### (≈ 4 lignes de code)\n",
    "    W1 = None\n",
    "    b1 = None\n",
    "    W2 = None\n",
    "    b2 = None\n",
    "    ### Fin du code ###\n",
    "    \n",
    "    # Implémentez la forward porpagation pour calculer A2 (probabilités)\n",
    "    ### Début du code ### (≈ 4 lignes de code)\n",
    "    Z1 = None\n",
    "    A1 = None\n",
    "    Z2 = None\n",
    "    A2 = None\n",
    "    ### Fin du code ###\n",
    "    \n",
    "    assert(A2.shape == (1, X.shape[1]))\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_assess, parameters = forward_propagation_test_case()\n",
    "A2, cache = forward_propagation(X_assess, parameters)\n",
    "\n",
    "# Note: on utilise la moyenne ici pour vérifier que vos résultats matchent avec les notres\n",
    "print(np.mean(cache['Z1']) ,np.mean(cache['A1']),np.mean(cache['Z2']),np.mean(cache['A2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultat attendu**:\n",
    "<table style=\"width:50%\">\n",
    "  <tr>\n",
    "    <td> 0.262818640198 0.091999045227 -1.30766601287 0.212877681719 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que vous avez calculé $A^{[2]}$ (dans la variable Python \"`A2`\"), qui contient $a^{[2](i)}$ pour tous les exemples, vous pouvez calculer le coût de la manière suivante:\n",
    "\n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large{(} \\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right) \\large{)} \\small\\tag{13}$$\n",
    "\n",
    "**Exercice**: Implementez `compute_cost()` pour calculer la valeur du coût $J$.\n",
    "\n",
    "**Instructions**:\n",
    "- Il y a plusieurs façon d'implémenter la loss cross-entropy. Pour vous aider, on vous met ici comment on aurait calculé $- \\sum\\limits_{i=0}^{m}  y^{(i)}\\log(a^{[2](i)})$:\n",
    "```python\n",
    "logprobs = np.multiply(np.log(A2),Y)\n",
    "cost = - np.sum(logprobs)                # pas besoin d'utiliser une boucle for !\n",
    "```\n",
    "\n",
    "(vous pouvez utiliser `np.multiply()` puis `np.sum()` ou directement `np.dot()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y, parameters):\n",
    "    \"\"\"\n",
    "    Calculez le coût cross-entropy dont la formule se trouve dans l'équation (13)\n",
    "    \n",
    "    Arguments:\n",
    "    A2 -- L'output de la sigmoïde de la deuxième activation, de shape (1, nombre d'exemples)\n",
    "    Y -- vecteur contenant les labels, de shape (1, number of examples)\n",
    "    parameters -- dictionnaire python contenant vos paramètres W1, b1, W2 and b2\n",
    "    \n",
    "    Return:\n",
    "    cost -- coût cross-entropy selon l'équation (13)\n",
    "    \"\"\"\n",
    "    m = Y.shape[1] # nombre d'exemples\n",
    "\n",
    "    # Calculez la cross entropy\n",
    "    ### Début du code ### (≈ 2 lignes de code)\n",
    "    logprobs = None\n",
    "    cost = None\n",
    "    ### Fin du code ###\n",
    "    \n",
    "    cost = np.squeeze(cost)     \n",
    "    assert(isinstance(cost, float))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A2, Y_assess, parameters = compute_cost_test_case()\n",
    "\n",
    "print(\"cost = \" + str(compute_cost(A2, Y_assess, parameters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultat attendu**:\n",
    "<table style=\"width:20%\">\n",
    "  <tr>\n",
    "    <td>cost</td>\n",
    "    <td> 0.693058761... </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grâce au dictionnaire \"cache\" que vous avez calculé pendant la forward propagation, vous pouvez maintenant implémenter la backward propagation.\n",
    "\n",
    "**Exercice**: Implementez la fonction `backward_propagation()`.\n",
    "\n",
    "**Instructions**:\n",
    "La backpropagation est généralement la partie la plus compliquée en deep learning (la plus mathématique). Pour vous aider, on vous a mis ici les différentes étapes de la backpropagation.  \n",
    "\n",
    "<img src=\"images/grad_summary.png\" style=\"width:600px;height:300px;\">\n",
    "\n",
    "<!--\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } = \\frac{1}{m} (a^{[2](i)} - y^{(i)})$\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial W_2 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } a^{[1] (i) T} $\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial b_2 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)}}}$\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} } =  W_2^T \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } * ( 1 - a^{[1] (i) 2}) $\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial W_1 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} }  X^T $\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} _i }{ \\partial b_1 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)}}}$\n",
    "\n",
    "- Note that $*$ denotes elementwise multiplication.\n",
    "- The notation you will use is common in deep learning coding:\n",
    "    - dW1 = $\\frac{\\partial \\mathcal{J} }{ \\partial W_1 }$\n",
    "    - db1 = $\\frac{\\partial \\mathcal{J} }{ \\partial b_1 }$\n",
    "    - dW2 = $\\frac{\\partial \\mathcal{J} }{ \\partial W_2 }$\n",
    "    - db2 = $\\frac{\\partial \\mathcal{J} }{ \\partial b_2 }$\n",
    "    \n",
    "!-->\n",
    "\n",
    "- Indice:\n",
    "    - Pour calculer dZ1 vous devrez calculer $g^{[1]'}(Z^{[1]})$. Comme $g^{[1]}(.)$ est la fonction d'activation tanh, si $a = g^{[1]}(z)$ alors $g^{[1]'}(z) = 1-a^2$. Vous pourrez ensuite calculer \n",
    "    $g^{[1]'}(Z^{[1]})$ avec `(1 - np.power(A1, 2))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    \"\"\"\n",
    "    Implémentez la backward propagation en suivant les instructions ci-dessus\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- dictionnaire python contenant vos paramètres\n",
    "    cache -- dictionnaire python contenant \"Z1\", \"A1\", \"Z2\"  et \"A2\".\n",
    "    X -- données en entrée de shape (2, nombre d'exemples)\n",
    "    Y -- vecteur des labels de shape (1, nombre d'exemples)\n",
    "    \n",
    "    Return:\n",
    "    grads -- dictionnaire python contenant vos gradients\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # Récuperez W1 et W2 à partie de parameters\n",
    "    ### Début du code ### (≈ 2 lignes de code)\n",
    "    W1 = None\n",
    "    W2 = None\n",
    "    ### Fin du code ###\n",
    "        \n",
    "    # Récupérez également A1 et A2 depuis le dictionnaire \"cache\".\n",
    "    ### Début du code ### (≈ 2 lignes de code)\n",
    "    A1 = None\n",
    "    A2 = None\n",
    "    ### Fin du code ###\n",
    "    \n",
    "    # Backward propagation: calculez les gradients dW1, db1, dW2, db2. \n",
    "    ### Début du code ### (≈ 6 lignes de code, correspondant aux 6 équations de la cellule au-dessus)\n",
    "    dZ2 = None\n",
    "    dW2 = None\n",
    "    db2 = None\n",
    "    dZ1 = None\n",
    "    dW1 = None\n",
    "    db1 = None\n",
    "    ### Fin du code ###\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters, cache, X_assess, Y_assess = backward_propagation_test_case()\n",
    "\n",
    "grads = backward_propagation(parameters, cache, X_assess, Y_assess)\n",
    "print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
    "print (\"db1 = \"+ str(grads[\"db1\"]))\n",
    "print (\"dW2 = \"+ str(grads[\"dW2\"]))\n",
    "print (\"db2 = \"+ str(grads[\"db2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultat attendu**:\n",
    "\n",
    "\n",
    "\n",
    "<table style=\"width:80%\">\n",
    "  <tr>\n",
    "    <td>dW1</td>\n",
    "    <td> [[ 0.00301023 -0.00747267]\n",
    " [ 0.00257968 -0.00641288]\n",
    " [-0.00156892  0.003893  ]\n",
    " [-0.00652037  0.01618243]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>db1</td>\n",
    "    <td>  [[ 0.00176201]\n",
    " [ 0.00150995]\n",
    " [-0.00091736]\n",
    " [-0.00381422]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>dW2</td>\n",
    "    <td> [[ 0.00078841  0.01765429 -0.00084166 -0.01022527]] </td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "  <tr>\n",
    "    <td>db2</td>\n",
    "    <td> [[-0.16655712]] </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice**: Implementez la fonction update_parameters. Utilisez la descente de gradient. Vous devez vous servir de (dW1, db1, dW2, db2) afin d'update (W1, b1, W2, b2).\n",
    "\n",
    "**Règle générale de la descente de gradient**: $ \\theta = \\theta - \\alpha \\frac{\\partial J }{ \\partial \\theta }$ avec $\\alpha$ le learning rate et $\\theta$ représentant le paramètre.\n",
    "\n",
    "**Illustration**: Vous pouvez comparer ci-dessous la différence avec un bon learning rate (convergence) et un mauvais learning rate (divergence). Crédits animation: Adam Harley.\n",
    "\n",
    "<img src=\"images/sgd.gif\" style=\"width:400;height:400;\"> <img src=\"images/sgd_bad.gif\" style=\"width:400;height:400;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, lr = 1.2):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    parameters -- dictionnaire python contenant vos paramètres\n",
    "    grads -- dictionnaire python contenant vos gradients \n",
    "    \n",
    "    Return:\n",
    "    parameters -- dictionnaire python contenant vos paramètres updatés\n",
    "    \"\"\"\n",
    "    # Récuperer vos paramètres\n",
    "    ### Début du code ### (≈ 4 lignes de code)\n",
    "    W1 = None\n",
    "    b1 = None\n",
    "    W2 = None\n",
    "    b2 = None\n",
    "    ### Fin du code ###\n",
    "    \n",
    "    # Récupérez vos gradients\n",
    "    ### Début du code ### (≈ 4 lignes de code)\n",
    "    dW1 = None\n",
    "    db1 = None\n",
    "    dW2 = None\n",
    "    db2 = None\n",
    "    ## Fin du code ###\n",
    "    \n",
    "    # Updatez vos paramètres \n",
    "    ### Début du code ### (≈ 4 lignes de code)\n",
    "    W1 = None\n",
    "    b1 = None\n",
    "    W2 = None\n",
    "    b2 = None\n",
    "    ### Fin du code ###\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parameters, grads = update_parameters_test_case()\n",
    "parameters = update_parameters(parameters, grads)\n",
    "\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultat attendu**:\n",
    "\n",
    "\n",
    "<table style=\"width:80%\">\n",
    "  <tr>\n",
    "    <td>W1</td>\n",
    "    <td> [[-0.00643025  0.01936718]\n",
    " [-0.02410458  0.03978052]\n",
    " [-0.01653973 -0.02096177]\n",
    " [ 0.01046864 -0.05990141]]</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>b1</td>\n",
    "    <td> [[ -1.02420756e-06]\n",
    " [  1.27373948e-05]\n",
    " [  8.32996807e-07]\n",
    " [ -3.20136836e-06]]</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>W2</td>\n",
    "    <td> [[-0.01041081 -0.04463285  0.01758031  0.04747113]] </td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "  <tr>\n",
    "    <td>b2</td>\n",
    "    <td> [[ 0.00010457]] </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - Intégrez les parties 4.1, 4.2 et 4.3 dans nn_model() ####\n",
    "\n",
    "**Exercice**: Construisez votre réseau de neurones dans `nn_model()`.\n",
    "\n",
    "**Instructions**: Le réseau de neurones doit utiliser vos fonctions précédentes dans le bon ordre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- dataset de shape (2, nombre d'exemples)\n",
    "    Y -- labels de shape (1, nombre d'exemples)\n",
    "    n_h -- size de la couche cachée\n",
    "    num_iterations -- Nombre d'itérations dans la boucle \n",
    "    print_cost -- si True, print le coût toutes les 1000 itérations\n",
    "    \n",
    "    Return:\n",
    "    parameters -- paramètres entraînés. Ce sont ces paramètres qui seront utilisés pour de nouvelles données.\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[2]\n",
    "    \n",
    "    # Initialise les paramètres, puis récupère W1, b1, W2, b2. Inputs: \"n_x, n_h, n_y\". Outputs = \"W1, b1, W2, b2, parameters\".\n",
    "    ### Début du code ### (≈ 5 lignes de code)\n",
    "    parameters = None\n",
    "    W1 = None\n",
    "    b1 = None\n",
    "    W2 = None\n",
    "    b2 = None]\n",
    "    ### Fin du code ###\n",
    "    \n",
    "    # Boucle\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        ### Début du code ### (≈ 4 lignes de code)\n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "        A2, cache = None\n",
    "        \n",
    "        # Fonction de coût. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
    "        cost = None\n",
    " \n",
    "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        grads = None\n",
    " \n",
    "        # Update des paramètres. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        parameters = None\n",
    "        \n",
    "        ### Fin du code ###\n",
    "        \n",
    "        # Print le coût toutes les 1000 iterations\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Coût après itération %i: %f\" %(i, cost))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_assess, Y_assess = nn_model_test_case()\n",
    "parameters = nn_model(X_assess, Y_assess, 4, num_iterations=10000, print_cost=True)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultat attendu**:\n",
    "\n",
    "<table style=\"width:90%\">\n",
    "\n",
    "<tr> \n",
    "    <td> \n",
    "        coût après itération 0\n",
    "    </td>\n",
    "    <td> \n",
    "        0.693207\n",
    "    </td>\n",
    "</tr>\n",
    "\n",
    "<tr> \n",
    "    <td> \n",
    "        <center> $\\vdots$ </center>\n",
    "    </td>\n",
    "    <td> \n",
    "        <center> $\\vdots$ </center>\n",
    "    </td>\n",
    "</tr>\n",
    "\n",
    "  <tr>\n",
    "    <td>W1</td>\n",
    "    <td> [[-0.60314397  1.127818  ]\n",
    " [-0.74257953  1.3776121 ]\n",
    " [-0.69186287  1.27565127]\n",
    " [-0.7349128   1.36877347]]</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>b1</td>\n",
    "    <td> [[0.26051203]\n",
    " [0.35648363]\n",
    " [0.31850012]\n",
    " [0.35292858]] </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>W2</td>\n",
    "    <td> [[-2.10582454 -3.16994587 -2.70047639 -3.11996342]] </td> \n",
    "  </tr>\n",
    "  \n",
    "\n",
    "  <tr>\n",
    "    <td>b2</td>\n",
    "    <td> [[0.21989657]] </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Prédictions\n",
    "\n",
    "**Exercice**: Utilisez votre modèle pour prédire de nouvelles données. Implémentez predict().\n",
    "Utilisez la forward propagation\n",
    "\n",
    "**Rappel**: predictions = $y_{prediction} = \\mathbb 1 \\text{{activation > 0.5}} = \\begin{cases}\n",
    "      1 & \\text{si}\\ activation > 0.5 \\\\\n",
    "      0 & \\text{sinon}\n",
    "    \\end{cases}$  \n",
    "    \n",
    "Par exemple, si vous voulez définir les éléments d'une matrice X à 0 ou 1 en fonction d'un seuil, vous pouvez faire: ```X_new = (X > threshold)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    \"\"\"\n",
    "    Grâce aux paramètres appris, prédisez la classe pour chaque exemple de X\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- dictionnaire python contenant vos paramètres\n",
    "    X -- données en entrée de siwe (n_x, m)\n",
    "    \n",
    "    Returns\n",
    "    predictions -- vecteur des prédictions (rouge: 0 / bleu: 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calcule les propabilités en utilisant la forward propagation, et classifie en 0 ou 1 grâce au seuil défini comme 0.5\n",
    "    ### Début du code ### (≈ 2 lignes de code)\n",
    "    A, cache = None\n",
    "    predictions = None\n",
    "    ### Fin du code ###\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parameters, X_assess = predict_test_case()\n",
    "\n",
    "predictions = predict(parameters, X_assess)\n",
    "print(\"moyenne des predictions = \" + str(np.mean(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultat attendu**: \n",
    "\n",
    "\n",
    "<table style=\"width:40%\">\n",
    "  <tr>\n",
    "    <td>moyenne des predictions</td>\n",
    "    <td> 0.666666666667 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant entraîner notre modèle sur notre jeu de données. Exécutez le code suivant pour tester votre modèle avec une couche cachée de $n_h$ neurones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_h = 5\n",
    "parameters = nn_model(X, Y, n_h = n_h, num_iterations = 10000, print_cost=True)\n",
    "\n",
    "# Plot la decision boundary\n",
    "try:\n",
    "    plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y)\n",
    "except:\n",
    "    print(\"Suite à un problème de version matplotlib, vous ne voyez pas les points initiaux. Reprenez le graphique au début du notebook et imaginez les points comme étant plot.\")\n",
    "    pass\n",
    "plt.title(\"Decision Boundary pour une couche cachée de size \" + str(n_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultat attendu**:\n",
    "\n",
    "<table style=\"width:40%\">\n",
    "  <tr>\n",
    "    <td>Coût après itération 9000</td>\n",
    "    <td> 0.178517 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print l'accurary\n",
    "predictions = predict(parameters, X)\n",
    "print ('Accuracy: %d' % float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultat attendu**: \n",
    "\n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "    <td>Accuracy</td>\n",
    "    <td> 91% </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accurary est beaucoup plus élevé que celui de la régression logistique. Le modèle a pu apprendre le pattern des feuilles de la fleur. Contrairement à la régression logistique, les réseaux de neurones profonds sont capables de traiter des problèmes non linéaires.\n",
    "\n",
    "Essayez maintenant avec plusieurs nombres de neurones différents dans la couche cachée. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 - Tuning du nombre de neurones dans la couche cachée ###\n",
    "\n",
    "Exécutez le code suivant. Cela devrait prendre 1-2 minutes. Vous observerez des comportements différents du modèle selon le nombre de neurones que vous aurez défini dans la couche cachée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cela devrait prendre 2 minutes\n",
    "\n",
    "plt.figure(figsize=(16, 32))\n",
    "hidden_layer_sizes = [1, 2, 3, 4, 5, 20, 50]\n",
    "for i, n_h in enumerate(hidden_layer_sizes):\n",
    "    plt.subplot(5, 2, i+1)\n",
    "    plt.title('Hidden Layer of size %d' % n_h)\n",
    "    parameters = nn_model(X, Y, n_h, num_iterations = 5000)\n",
    "    try:\n",
    "        plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y)\n",
    "    except:\n",
    "        print(\"Suite à un problème de version matplotlib, vous ne voyez pas les points initiaux. Reprenez le graphique au début du notebook et imaginez les points comme étant plot.\")\n",
    "    predictions = predict(parameters, X)\n",
    "    accuracy = float((np.dot(Y,predictions.T) + np.dot(1-Y,1-predictions.T))/float(Y.size)*100)\n",
    "    print (\"Accuracy for {} hidden units: {} %\".format(n_h, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "- Le plus gros modèle est capable de mieux classifier le jeu de données de train, jusqu'à overfitter les données. \n",
    "- Le meilleur modèle semble être celui avec 5 neurones.\n",
    "\n",
    "Une méthode pour éviter l'overfitting est la régularisation. Nous aurons peut etre l'occasion de voir ça dans un futur workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "- http://scs.ryerson.ca/~aharley/neural-networks/\n",
    "- http://cs231n.github.io/neural-networks-case-study/"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "wRuwL",
   "launcher_item_id": "NI888"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
